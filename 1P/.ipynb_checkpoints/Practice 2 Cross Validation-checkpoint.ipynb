{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a70936d",
   "metadata": {},
   "source": [
    "# Practice 2: Cross Validation\n",
    "\n",
    "**Ojeda Contreras Braulio Melquisedec**\n",
    "\n",
    "**October 28th, 2022**\n",
    "\n",
    "*Requirements:*\n",
    "\n",
    "Using the weatherAUS.csv  dataset do the following:\n",
    "1. Load the dataset into a pandas dataframe\n",
    "2. Divide the dataset in training set (80%) and test set (20%) ensuring blending them\n",
    "3. Using the training set create the next validation sets through cross validation\n",
    "    - 3 folds\n",
    "    - 5 folds\n",
    "    - 10 folds\n",
    "4. Create the needed classes to store the created data sets\n",
    "5. Save in CSV files the data and their tags of each validation set.\n",
    "    - data_validation_train_$<$total_folds$>$_$<$fold_number$>$.csv\n",
    "    - target_validation_train_$<$total_folds$>$_$<$fold_number$>$.csv\n",
    "    - data_test_$<$total_folds$>$_$<$fold_number$>$.csv\n",
    "    - target_test_$<$total_folds$>$_$<$fold_number$>$.csv\n",
    "6. Save in CSV files the data and their tags of test set:\n",
    "    - data_test.csv\n",
    "    - target_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "543573f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19bf417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining data assignment functions\n",
    "class validation_set:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "class test_set:\n",
    "    def __init__(self, X_test, y_test):\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "class data_set:\n",
    "    def __init__(self, validation_set, test_set):\n",
    "        self.validation_set = validation_set\n",
    "        self.test_set = test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a03a7b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to save our distinct data in CSV files\n",
    "def create_csv(file_name, data, col_names, list_opt = False):\n",
    "    new_data = data.tolist()\n",
    "\n",
    "    with open(file_name, 'w', newline='') as f:\n",
    "        if list_opt:\n",
    "            new_new_data = [[i] for i in new_data]\n",
    "        else:\n",
    "            new_new_data = new_data\n",
    "        \n",
    "        write = csv.writer(f)\n",
    "        write.writerow(col_names)\n",
    "        write.writerows(new_new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d948f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to get training and test set\n",
    "def generate_train_test(file_name, tag_name):\n",
    "    df = pd.read_csv(file_name, sep = ',', engine = 'python')\n",
    "    X = df.drop(tag_name, axis = 1).values\n",
    "    y = df[tag_name].values\n",
    "    \n",
    "    columns = list(df.columns.values)\n",
    "    subcolumns = ','.join([column for column in columns if column != tag_name])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True)\n",
    "    X_columns = subcolumns\n",
    "    y_columns = tag_name\n",
    "    return [X_train, y_train, X_test, y_test, X_columns, y_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88ec5d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function which implements cross validation\n",
    "def generate_folds(data, k):\n",
    "    X_train = data[0]\n",
    "    y_train = data[1]\n",
    "    X_test = data[2]\n",
    "    y_test = data[3]\n",
    "    X_columns = data[4]\n",
    "    y_columns = data[5]\n",
    "    \n",
    "    print('Cross Validation k =', k)\n",
    "    validation_sets = []\n",
    "    kf = KFold(n_splits = k)\n",
    "    c = 0\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        c = c + 1\n",
    "        X_train_v, X_test_v = X_train[train_index], X_train[test_index]\n",
    "        y_train_v, y_test_v = y_train[train_index], y_train[test_index]\n",
    "        validation_sets.append(validation_set(X_train_v, y_train_v, X_test_v, y_test_v))\n",
    "        \n",
    "        create_csv(file_name = \"./p2_weatherAUS/data_validation_train_\" + str(k) + \"_\" + str(c) + \".csv\", \n",
    "                    data = X_train_v, col_names = X_columns)\n",
    "        \n",
    "        create_csv(file_name = \"./p2_weatherAUS/target_validation_train_\" + str(k) + \"_\" + str(c) + \".csv\", \n",
    "                    data = y_train_v, col_names = y_columns, list_opt = True)\n",
    "        \n",
    "        create_csv(file_name = \"./p2_weatherAUS/data_test_\" + str(k) + \"_\" + str(c) + \".csv\", \n",
    "                    data = X_test_v, col_names = X_columns)\n",
    "        \n",
    "        create_csv(file_name = \"./p2_weatherAUS/target_test_\" + str(k) + \"_\" + str(c) + \".csv\", \n",
    "                    data = y_test_v, col_names = y_columns, list_opt = True) \n",
    "    \n",
    "    my_test_set = test_set(X_test, y_test)\n",
    "    my_data_set = data_set(validation_sets, my_test_set)\n",
    "    \n",
    "    return (my_data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4ad8ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting training and test sets\n",
    "data = generate_train_test('./weatherAUS.csv', 'RainTomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db8a244c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation k = 3\n",
      "Completed\n",
      "Cross Validation k = 5\n",
      "Completed\n",
      "Cross Validation k = 10\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "# Executing cross validation\n",
    "ks = [3, 5, 10]\n",
    "for k in ks:\n",
    "    new_data = generate_folds(data, k)\n",
    "    \n",
    "    # Save dataset in pickle\n",
    "    dataset_file = open('./p2_weatherAUS/dataset_f' + str(k) + '.pkl', 'wb')\n",
    "    pickle.dump(new_data, dataset_file)\n",
    "    dataset_file.close()\n",
    "    print('Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cd41a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving data from test set\n",
    "create_csv(file_name = \"./p2_weatherAUS/data_test.csv\", data = new_data.test_set.X_test, col_names = data[4])\n",
    "create_csv(file_name = \"./p2_weatherAUS/target_test.csv\", data = new_data.test_set.y_test, col_names = data[5], list_opt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2e5dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cursoml5am1] *",
   "language": "python",
   "name": "conda-env-cursoml5am1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
