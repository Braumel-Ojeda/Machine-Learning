{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9278d504",
   "metadata": {},
   "source": [
    "## Practice 5: Logistic Regression\n",
    "\n",
    "**Ojeda Contreras Braulio Melquisedec**\n",
    "\n",
    "**December 2nd, 2022**\n",
    "\n",
    "*Requirements:*\n",
    "\n",
    "Using the breast-cancer.csv dataset do the following:\n",
    "\n",
    "1. Load the dataset into a pandas dataframe\n",
    "    - Size column is the feature from the houses\n",
    "    - Diagnosis column is the value to be predicted\n",
    "2. Divide the dataset in training set (90%) and test set (10%) ensuring to shuffle them and fixing random_state as zero\n",
    "3. Using the training set train a logistic regression model\n",
    "4. Using the generated model classify the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9739c42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from  sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30f38a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data.frame with the file given\n",
    "df = pd.read_csv('./breast-cancer.csv', sep=',', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff2df9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>844359</td>\n",
       "      <td>M</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84458202</td>\n",
       "      <td>M</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>...</td>\n",
       "      <td>17.06</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>844981</td>\n",
       "      <td>M</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>...</td>\n",
       "      <td>15.49</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84501001</td>\n",
       "      <td>M</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>...</td>\n",
       "      <td>15.09</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "5    843786         M        12.45         15.70           82.57      477.1   \n",
       "6    844359         M        18.25         19.98          119.60     1040.0   \n",
       "7  84458202         M        13.71         20.83           90.20      577.9   \n",
       "8    844981         M        13.00         21.82           87.50      519.8   \n",
       "9  84501001         M        12.46         24.04           83.97      475.9   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760         0.30010              0.14710   \n",
       "1          0.08474           0.07864         0.08690              0.07017   \n",
       "2          0.10960           0.15990         0.19740              0.12790   \n",
       "3          0.14250           0.28390         0.24140              0.10520   \n",
       "4          0.10030           0.13280         0.19800              0.10430   \n",
       "5          0.12780           0.17000         0.15780              0.08089   \n",
       "6          0.09463           0.10900         0.11270              0.07400   \n",
       "7          0.11890           0.16450         0.09366              0.05985   \n",
       "8          0.12730           0.19320         0.18590              0.09353   \n",
       "9          0.11860           0.23960         0.22730              0.08543   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "5  ...         15.47          23.75           103.40       741.6   \n",
       "6  ...         22.88          27.66           153.20      1606.0   \n",
       "7  ...         17.06          28.14           110.60       897.0   \n",
       "8  ...         15.49          30.73           106.20       739.3   \n",
       "9  ...         15.09          40.68            97.65       711.4   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "5            0.1791             0.5249           0.5355                0.1741   \n",
       "6            0.1442             0.2576           0.3784                0.1932   \n",
       "7            0.1654             0.3682           0.2678                0.1556   \n",
       "8            0.1703             0.5401           0.5390                0.2060   \n",
       "9            0.1853             1.0580           1.1050                0.2210   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "5          0.3985                  0.12440  \n",
       "6          0.3063                  0.08368  \n",
       "7          0.3196                  0.11510  \n",
       "8          0.4378                  0.10720  \n",
       "9          0.4366                  0.20750  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b25901c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicating tag column name\n",
    "tag_name = 'diagnosis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c329e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.4230200e+05, 1.7990000e+01, 1.0380000e+01, ..., 2.6540000e-01,\n",
       "        4.6010000e-01, 1.1890000e-01],\n",
       "       [8.4251700e+05, 2.0570000e+01, 1.7770000e+01, ..., 1.8600000e-01,\n",
       "        2.7500000e-01, 8.9020000e-02],\n",
       "       [8.4300903e+07, 1.9690000e+01, 2.1250000e+01, ..., 2.4300000e-01,\n",
       "        3.6130000e-01, 8.7580000e-02],\n",
       "       ...,\n",
       "       [9.2695400e+05, 1.6600000e+01, 2.8080000e+01, ..., 1.4180000e-01,\n",
       "        2.2180000e-01, 7.8200000e-02],\n",
       "       [9.2724100e+05, 2.0600000e+01, 2.9330000e+01, ..., 2.6500000e-01,\n",
       "        4.0870000e-01, 1.2400000e-01],\n",
       "       [9.2751000e+04, 7.7600000e+00, 2.4540000e+01, ..., 0.0000000e+00,\n",
       "        2.8710000e-01, 7.0390000e-02]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Corpus without tags\n",
    "X = df.drop(tag_name, axis = 1).values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6d0ac29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'B', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'M', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M',\n",
       "       'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'M', 'B', 'M',\n",
       "       'M', 'B', 'B', 'B', 'M', 'M', 'B', 'M', 'M', 'M', 'B', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'M', 'M', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'M',\n",
       "       'B', 'M', 'M', 'B', 'M', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B',\n",
       "       'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'M', 'M',\n",
       "       'B', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M',\n",
       "       'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M',\n",
       "       'B', 'M', 'M', 'M', 'M', 'B', 'M', 'M', 'M', 'B', 'M', 'B', 'M',\n",
       "       'B', 'B', 'M', 'B', 'M', 'M', 'M', 'M', 'B', 'B', 'M', 'M', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B',\n",
       "       'B', 'B', 'B', 'M', 'B', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'M', 'B',\n",
       "       'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'M', 'B', 'M', 'M', 'M', 'B', 'M', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M',\n",
       "       'B', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'B', 'B', 'M', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'M', 'M', 'M', 'M', 'M', 'M', 'B'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tags\n",
    "y = df[tag_name].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3295164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a03e32d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test) #la clase predicha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "677b4624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mReal class\u001b[0m\n",
      " ['M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'M'\n",
      " 'M' 'M' 'M' 'M' 'B' 'B' 'M' 'B' 'B' 'M' 'B' 'M' 'B' 'M' 'B' 'M' 'B' 'M'\n",
      " 'B' 'M' 'B' 'M' 'M' 'B' 'M' 'B' 'B' 'M' 'B' 'B' 'B' 'M' 'M' 'M' 'M' 'B'\n",
      " 'B' 'B' 'B']\n"
     ]
    }
   ],
   "source": [
    "print ('\\033[1mReal class\\033[0m\\n', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b77135b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPredicted class\u001b[0m\n",
      " ['B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B']\n"
     ]
    }
   ],
   "source": [
    "print ('\\033[1mPredicted class\\033[0m\\n', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6b29009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion matrix\u001b[0m\n",
      "[[35  0]\n",
      " [22  0]]\n",
      "\n",
      "\u001b[1mAccuracy\u001b[0m\n",
      "% Correctly predicted instances: 61.4 %\n",
      "# Correctly predicted instances: 35 \n"
     ]
    }
   ],
   "source": [
    "print('\\033[1mConfusion matrix\\033[0m')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n\\033[1mAccuracy\\033[0m')\n",
    "print('% Correctly predicted instances:', round(accuracy_score(y_test, y_pred) * 100, 2), '%') \n",
    "print('# Correctly predicted instances:', accuracy_score(y_test, y_pred, normalize = False), '') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "451b338b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1dcbe40acd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred,labels= clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9af550f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mProbability of belonging to a class\u001b[0m\n",
      "\u001b[94m [[0.50005645 0.49994355]\n",
      " [0.50056171 0.49943829]\n",
      " [0.50005606 0.49994394]\n",
      " [0.500055   0.499945  ]\n",
      " [0.5000527  0.4999473 ]\n",
      " [0.50005648 0.49994352]\n",
      " [0.50000556 0.49999444]\n",
      " [0.5000551  0.4999449 ]\n",
      " [0.50005678 0.49994322]\n",
      " [0.5000554  0.4999446 ]\n",
      " [0.50005588 0.49994412]\n",
      " [0.50005311 0.49994689]\n",
      " [0.50005582 0.49994418]\n",
      " [0.50053698 0.49946302]\n",
      " [0.50005311 0.49994689]\n",
      " [0.50000537 0.49999463]\n",
      " [0.50005513 0.49994487]\n",
      " [0.50543705 0.49456295]\n",
      " [0.50000557 0.49999443]\n",
      " [0.50005455 0.49994545]\n",
      " [0.50005262 0.49994738]\n",
      " [0.50054938 0.49945062]\n",
      " [0.50005625 0.49994375]\n",
      " [0.5005431  0.4994569 ]\n",
      " [0.50055557 0.49944443]\n",
      " [0.50005576 0.49994424]\n",
      " [0.5000537  0.4999463 ]\n",
      " [0.50521894 0.49478106]\n",
      " [0.50055546 0.49944454]\n",
      " [0.50005533 0.49994467]\n",
      " [0.50005385 0.49994615]\n",
      " [0.50005194 0.49994806]\n",
      " [0.50056178 0.49943822]\n",
      " [0.5053461  0.4946539 ]\n",
      " [0.50005357 0.49994643]\n",
      " [0.50529629 0.49470371]\n",
      " [0.50054327 0.49945673]\n",
      " [0.5000534  0.4999466 ]\n",
      " [0.500056   0.499944  ]\n",
      " [0.5005554  0.4994446 ]\n",
      " [0.50005583 0.49994417]\n",
      " [0.50055542 0.49944458]\n",
      " [0.50005213 0.49994787]\n",
      " [0.50005687 0.49994313]\n",
      " [0.50056176 0.49943824]\n",
      " [0.50005711 0.49994289]\n",
      " [0.50005376 0.49994624]\n",
      " [0.50543973 0.49456027]\n",
      " [0.50005392 0.49994608]\n",
      " [0.50522705 0.49477295]\n",
      " [0.50005216 0.49994784]\n",
      " [0.505397   0.494603  ]\n",
      " [0.50005349 0.49994651]\n",
      " [0.55594112 0.44405888]\n",
      " [0.50005502 0.49994498]\n",
      " [0.5000554  0.4999446 ]\n",
      " [0.50543663 0.49456337]] \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test) \n",
    "print ('\\033[1mProbability of belonging to a class\\033[0m\\n\\033[94m', y_pred_proba, '\\033[0m')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
